<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Work | laurent-orseau.com</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Jules HTML Cleaner">
    <link rel="canonical" href="work.html">
    <link rel="stylesheet" href="onewebstatic/styles.css">
    <style>
        /* Basic structural styles - more in styles.css */
        body { margin: 0; padding: 0; font-family: sans-serif; line-height: 1.6; }
        .container { max-width: 900px; margin: 20px auto; padding: 0 20px; }
        .site-header { background-color: #f0f0f0; padding: 10px 0; margin-bottom: 20px;}
        .site-header .container { display: flex; justify-content: space-between; align-items: center; }
        .site-title a { font-size: 1.5em; font-weight: bold; text-decoration: none; color: #333; }
        .main-nav ul { list-style: none; padding: 0; margin: 0; display: flex; }
        .main-nav ul li { margin-left: 20px; }
        .main-nav ul li a { text-decoration: none; color: #333; }
        .main-nav ul li a.selected { font-weight: bold; }
        .site-footer { margin-top: 40px; padding: 20px 0; text-align: center; font-size: 0.9em; color: #777; border-top: 1px solid #eee; }

        /* Mobile menu - very basic for now */
        .mobile-header { display: none; } /* Will be handled by styles.css for responsiveness */
        .mobile-nav { display: none; }

        @media (max-width: 600px) {
            .site-header .container { flex-direction: column; align-items: flex-start; }
            .main-nav ul { flex-direction: column; width: 100%; }
            .main-nav ul li { margin: 5px 0; }
            /* Basic mobile menu toggle might be added via JS if needed, but keeping it simple first */
        }
    </style>
    
</head>
<body>
    <header class="site-header">
        <div class="container">
            <div class="site-title">
                <img src="img/orseau_w150.jpg" alt="Laurent Orseau">
                <a href="index.html">Laurent Orseau</a>
            </div>
            <nav class="main-nav">
                <ul>
                    <li><a href="index.html" class="">Home</a></li>
                    <li><a href="work.html" class="selected">Work</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <main class="container">

<p>Old professional webpage <a href="https://www6.inrae.fr/mia-paris/Equipes/Membres/Anciens/Laurent-Orseau">here</a> (≤2014).</p>
<br>
<h2>Highlights</h2>
<br>
<ul style="list-style-type: disc; padding-left: 20px;">
    <li style="margin-bottom: 1em;"><em><a href="https://www.ijcai.org/proceedings/2023/0624.pdf">Levin Tree Search with Context Models</a></em>
        (<a href="https://arxiv.org/abs/2305.16945">pdf_long</a>) describes a <strong>machine learning + search</strong> algorithm for deterministic search problems. By contrast to neural networks, we use algorithms and ideas from the online learning / compression literature which ensure that the <strong>loss function is convex</strong>. This also makes inference very fast (single cpu), though training still requires significant compute. Convexity is good for convergence guarantees and reproducibility, but more importantly it makes it clear what the model can learn, and what it cannot.&nbsp;<a href="https://ijcai-23.org/distinguished-paper-awards/">Distinguished paper award</a> at IJCAI 2023. [<a href="https://github.com/deepmind/levintreesearch_cm">source code and more</a>]</li>
    <li style="margin-bottom: 1em;">
        <p><em><a href="https://arxiv.org/abs/2112.14586">Isotuning With Applications To Scale-Free Online Learning</a>&nbsp;</em>(<a href="https://arxiv.org/pdf/2112.14586">pdf_long</a>) extends previous works on designing <strong>adaptive scale-free online-learning algorithm</strong> where the only parameter to set is a multiplicative constant. It develops the theory of three central ideas (<strong>isotuning, online correction, null updates</strong>) that are applied to various algorithms: FTRL, Mirror-Descent, Prod, AdaptMLProd, BOA, (Ada)Hedge, Soft-Bayes (arXiv 2021)</p>
    </li>
    <li style="margin-bottom: 1em;"><em><a href="https://arxiv.org/abs/2103.11505">Policy-Guided Heuristic Search with Guarantees</a>&nbsp;</em>(<a href="https://arxiv.org/pdf/2103.11505">pdf_long</a>) describes <strong>PHS</strong> algorithm, which is an extension of <strong>Levin Tree Search</strong> (see below) to also learn and make use of a <strong>heuristic</strong> function. We provide <strong>search-cost&nbsp; guarantees</strong> that relate to the quality of the policy and of the heuristic. Furthermore, if the heuristic is PHS-admissible, the guarantee is at least as good as the LTS guarantee that doesn't use a heuristic. [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17469">AAAI 2021</a>] [<a href="https://github.com/levilelis/h-levin">github</a>]</li>
    <li style="margin-bottom: 1em;"><em><a href="https://arxiv.org/abs/2006.12156">Logarithmic Pruning is All You Need</a></em> (<a href="https://arxiv.org/pdf/2006.12156">pdf_long</a>)
        <p>The <strong>strong Lottery Ticket Hypothesis</strong>, proven by Malach et al. with polynomial bounds, says that every sufficiently overparameterized network contains a subnetwork that, even without training, achieves comparable accuracy to the trained large network. This theorem, however, relies on a number of strong assumptions and guarantees a polynomial factor on the size of the large network compared to the target function. We remove the most limiting assumptions of this previous work while providing significantly tighter bounds: <strong>the overparameterized network only needs a logarithmic factor (in all variables but depth) number of neurons per weight of the target subnetwork</strong>. [<a href="https://proceedings.neurips.cc/paper/2020/hash/1e9491470749d5b0e361ce4f0b24d037-Abstract.html">NeurIPS 2020</a>]</p>
    </li>
    <li style="margin-bottom: 1em;"><span><em><a href="https://arxiv.org/abs/1907.13062">Iterative Budgeted Exponential Search</a></em> (<a href="https://arxiv.org/pdf/1907.13062">pdf_long</a>) received a special mention at the IJCAI 2019 opening ceremony, as it was the result of merging two independent submission to IJCAI. <strong>The IBEX framework solves two long-standing problems of heuristic search:</strong> The re-expansion problem of IDA* and the re-expansion problem of A* and B/B'. The DovIBEX variant relaxes some assumptions and may even solve problems outside heuristic search. <a href="https://www.cs.du.edu/~sturtevant/">Nathan Sturtevant</a> has some nice demos explaining the problem and solution (<a href="https://www.movingai.com/SAS/BTS/">IBEX</a> and <a href="https://www.movingai.com/SAS/">others</a>).&nbsp; [<a href="https://www.ijcai.org/proceedings/2019/0174">IJCAI_2019</a>] [<a href="https://webdocs.cs.ualberta.ca/~nathanst/talks/IBEX-slides.pdf">slides</a></span>]</li>
    <li style="margin-bottom: 1em;"><a href="https://arxiv.org/abs/1811.10928"><em>Levin Tree Search</em></a> <span> (</span><a href="https://arxiv.org/pdf/1811.10928">pdf_long</a><span>) is a new tree/graph search algorithm that uses a policy to guide the search, and comes with strict </span><strong>guarantees on search time</strong><span> that depend on the quality of the heuristic. One can then use this guarantee as a loss function to optimize the search time. [</span><a href="https://papers.nips.cc/paper/7582-single-agent-policy-tree-search-with-guarantees">NeurIPS_2018</a><span>] [<a href="https://github.com/deepmind/boxoban-levels/tree/master/unfiltered/test">test_set</a>]</span><br>
        <ul style="list-style-type: circle; padding-left: 20px; margin-top: 0.5em;">
            <li><span>Update 2021: See the PHS paper above (AAAI 2021) for a more general search-cost bound on the search cost, and a better learning procedure that uses this bound as a surrogate loss function.</span></li>
        </ul>
    </li>
    <li style="margin-bottom: 1em;"><span><span><em><a href="https://arxiv.org/abs/1901.02230">Soft-Bayes</a></em> (<a href="https://arxiv.org/pdf/1901.02230">pdf</a>) is the first tractable algorithm for the universal portfolio problem which has a <strong>guarantee that does <em>not</em> depend on the largest gradient</strong>. It requires O(N) computation steps per round for N experts, achieves O(√(</span>NT ln N)) regret over T rounds which is <strong>independent of the largest gradient</strong>, and has restarting guarantees. [<a href="http://proceedings.mlr.press/v76/orseau17a.html">ALT_2017</a>]</span>
        <ul style="list-style-type: circle; padding-left: 20px; margin-top: 0.5em;">
            <li><span>Update 2021: Appendix F of the <a href="https://arxiv.org/abs/2112.14586">Isotuning</a> paper shows that by using the isotuning learning rate, Soft-Bayes has an improved regret bound of <strong>O(√(mT ln N))</strong> where <strong>m is the number of 'good' predictors</strong>, without having to track them explicitly (by contrast to the 2017 paper).</span></li>
        </ul>
    </li>
    <li style="margin-bottom: 1em;"><span><a href="https://deepmind.com/research/publications/safely-interruptible-agents"><em>Safely Interruptible Agents</em></a> (<a href="https://intelligence.org/files/Interruptibility.pdf">pdf</a>) builds upon the idea of <a href="https://intelligence.org/files/Corrigibility.pdf">corrigibility</a> and Stuart Armstrong's principle of value indifference to build agents that <strong>learn to not care about being repeatedly interrupted</strong>, allowing the user/supervisor to repeatedly take control of the agent while the agent tends to indifferent to preventing it—and any opportunity cost will shift the balance toward not trying to prevent it. The concept is proven to work for both tabular MDP agents and universal intelligent agents. [<a href="http://auai.org/uai2016/proceedings/uai-2016-proceedings.pdf">UAI_2016</a>]</span></li>
    <li style="margin-bottom: 1em;"><span><a href="https://arxiv.org/abs/1805.12387">Agents and Devices</a> (<a href="https://arxiv.org/pdf/1805.12387">pdf</a>) is a fun little Bayesian experiment to define how an observer should see some object as a device or as a agent. An agent is better defined as optimizing an objective function, whereas a device is better seen as having a simple policy. [unpublished]</span></li>
</ul>
<br>
<p>See my Google Scholar <a href="https://scholar.google.com/citations?user=HVJjWlEAAAAJ&amp;hl=en&amp;oi=ao">page</a> for all other papers.</p>
<br>

<h2>Notes</h2>
<br>
<ul style="list-style-type: disc; padding-left: 20px;">
    <li style="margin-bottom: 1em;"><em><a href="https://www.ijcai.org/proceedings/2023/0624.pdf">A Quick Note on Online Gradient Descent with Momentum</a></em>
        Because it took me a while to find a paper that provides a non-vacuous regret bound for OGD with momentum, and this paper doesn't even tackle the simplest case of OGD, I thought this may be of help
        to someone else too. (<a href="docs/OGDM_regret.pdf">pdf</a>)</li>
</ul>
<br>
        
<h2>Awards</h2>
<ul style="list-style-type: disc; padding-left: 20px;">
    <li style="margin-bottom: 0.5em;"><span><a href="http://agi-conf.org/2011/prizes-support/">AGI 2011 Solomonof prize</a> with Mark Ring</span></li>
    <li style="margin-bottom: 0.5em;"><a href="http://agi-conference.org/2012/prizes/">AGI 2012 Kurzweil prize</a><span> with Mark Ring</span></li>
    <li style="margin-bottom: 0.5em;"><a href="http://auai.org/uai2016/program.php">UAI 2016 Best student paper</a><span> award with Jan Leike (main author), Tor Lattimore and Marcus Hutter</span></li>
    <li style="margin-bottom: 0.5em;"><span><a href="https://virtual.aistats.org/Conferences/2022/Reviewers">AISTATS 2022 Top 10% reviewer</a></span></li>
    <li style="margin-bottom: 0.5em;"><span><a href="https://ijcai-23.org/distinguished-paper-awards/">IJCAI 2023 Distinguished paper award</a> with&nbsp; Marcus Hutter and Levi Lelis</span></li>
</ul>

    </main>

    <footer class="site-footer">
        <div class="container">
            Copyright @ All Rights Reserved
        </div>
    </footer>

</body>
</html>
